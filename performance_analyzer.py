# -*- coding: utf-8 -*-
"""
æ€§èƒ½åˆ†æå™¨æ¨¡å—
ç”¨äºæ¯”è¾ƒä¸åŒæ±‚è§£å™¨çš„æ€§èƒ½ï¼Œç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import time
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
import numpy as np
import matplotlib

# ä½¿ç”¨å­—ä½“é…ç½®æ¨¡å—
try:
    from font_config import configure_chinese_font
    configure_chinese_font()
except ImportError:
    # å¦‚æœæ²¡æœ‰å­—ä½“é…ç½®æ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
    matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'KaiTi', 'FangSong', 'DejaVu Sans']
    matplotlib.rcParams['axes.unicode_minus'] = False

class PerformanceAnalyzer:
    """
    æ€§èƒ½åˆ†æå™¨ç±»
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨"""
        self.results = []
        self.comparison_data = None
        
    def add_result(self, solver_name, problem_name, result_summary):
        """
        æ·»åŠ æ±‚è§£ç»“æœ
        
        å‚æ•°:
            solver_name: æ±‚è§£å™¨åç§°
            problem_name: é—®é¢˜åç§°
            result_summary: ç»“æœæ‘˜è¦å­—å…¸
        """
        if result_summary:
            result_data = {
                'solver_name': solver_name,
                'problem_name': problem_name,
                'timestamp': datetime.now(),
                **result_summary
            }
            self.results.append(result_data)
            print(f"âœ… æ·»åŠ æ±‚è§£ç»“æœï¼š{solver_name} - {problem_name}")
        else:
            print(f"âŒ æ— æ•ˆçš„æ±‚è§£ç»“æœï¼š{solver_name} - {problem_name}")
    
    def compare_solvers(self, problem_data, solver_functions):
        """
        æ¯”è¾ƒå¤šä¸ªæ±‚è§£å™¨çš„æ€§èƒ½
        
        å‚æ•°:
            problem_data: é—®é¢˜æ•°æ®
            solver_functions: æ±‚è§£å™¨å‡½æ•°å­—å…¸ {'solver_name': function}
        """
        print("ğŸ”„ å¼€å§‹æ±‚è§£å™¨æ€§èƒ½æ¯”è¾ƒ...")
        print("="*60)
        
        problem_name = f"{problem_data['time_periods']}æœŸé—®é¢˜"
        
        for solver_name, solver_func in solver_functions.items():
            try:
                print(f"\nğŸš€ æµ‹è¯•æ±‚è§£å™¨ï¼š{solver_name}")
                print("-" * 40)
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # è°ƒç”¨æ±‚è§£å™¨
                solver = solver_func(problem_data)
                
                # è®°å½•æ€»æ—¶é—´
                total_time = time.time() - start_time
                
                if solver:
                    # è·å–ç»“æœæ‘˜è¦
                    summary = solver.get_result_summary()
                    if summary:
                        summary['total_time'] = total_time
                        self.add_result(solver_name, problem_name, summary)
                        print(f"âœ… {solver_name} æ±‚è§£æˆåŠŸï¼Œç”¨æ—¶ {total_time:.3f}ç§’")
                    else:
                        print(f"âŒ {solver_name} æ— æ³•è·å–ç»“æœæ‘˜è¦")
                else:
                    print(f"âŒ {solver_name} æ±‚è§£å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ {solver_name} è¿è¡Œå‡ºé”™ï¼š{e}")
        
        print("="*60)
        print("âœ… æ±‚è§£å™¨æ€§èƒ½æ¯”è¾ƒå®Œæˆ")
    
    def generate_comparison_report(self):
        """
        ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        """
        if not self.results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ±‚è§£ç»“æœ")
            return None
        
        print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒæŠ¥å‘Š...")
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(self.results)
        
        print("\n" + "="*80)
        print("ğŸ“ˆ æ±‚è§£å™¨æ€§èƒ½æ¯”è¾ƒæŠ¥å‘Š")
        print("="*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        print("ğŸ† æ±‚è§£å™¨åŸºæœ¬ä¿¡æ¯ï¼š")
        for solver in df['solver_name'].unique():
            solver_data = df[df['solver_name'] == solver]
            success_rate = len(solver_data[solver_data['status'] == 'Optimal']) / len(solver_data) * 100
            avg_time = solver_data['solve_time'].mean()
            print(f"  {solver:15s}: æˆåŠŸç‡ {success_rate:5.1f}%, å¹³å‡æ±‚è§£æ—¶é—´ {avg_time:.3f}ç§’")
        
        # æŒ‰é—®é¢˜åˆ†ç»„æ¯”è¾ƒ
        print(f"\nğŸ“Š è¯¦ç»†æ¯”è¾ƒç»“æœï¼š")
        comparison_table = df.pivot_table(
            index='problem_name', 
            columns='solver_name', 
            values=['solve_time', 'objective_value'],
            aggfunc='mean'
        )
        
        print(comparison_table)
        
        # æ‰¾å‡ºæœ€å¿«çš„æ±‚è§£å™¨
        print(f"\nğŸ¥‡ æ€§èƒ½æ’åï¼š")
        
        # æŒ‰æ±‚è§£æ—¶é—´æ’å
        time_ranking = df.groupby('solver_name')['solve_time'].mean().sort_values()
        print(f"æ±‚è§£é€Ÿåº¦æ’åï¼ˆå¹³å‡æ—¶é—´ï¼‰ï¼š")
        for i, (solver, time_val) in enumerate(time_ranking.items(), 1):
            print(f"  {i}. {solver}: {time_val:.3f}ç§’")
        
        # æŒ‰ç›®æ ‡å€¼æ’åï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        if 'objective_value' in df.columns and df['objective_value'].notna().any():
            obj_ranking = df.groupby('solver_name')['objective_value'].mean().sort_values()
            print(f"\næœ€ä¼˜è§£è´¨é‡æ’åï¼ˆå¹³å‡ç›®æ ‡å€¼ï¼‰ï¼š")
            for i, (solver, obj_val) in enumerate(obj_ranking.items(), 1):
                print(f"  {i}. {solver}: {obj_val:.2f}")
        
        # ä¿å­˜æ¯”è¾ƒæ•°æ®
        self.comparison_data = df
        
        print("="*80)
        
        return df
    
    def plot_performance_charts(self, save_plots=True, output_dir="results"):
        """
        ç»˜åˆ¶æ€§èƒ½æ¯”è¾ƒå›¾è¡¨
        
        å‚æ•°:
            save_plots: æ˜¯å¦ä¿å­˜å›¾è¡¨
            output_dir: è¾“å‡ºç›®å½•
        """
        if self.comparison_data is None or self.comparison_data.empty:
            print("âŒ æ²¡æœ‰æ¯”è¾ƒæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œgenerate_comparison_report()")
            return
        
        print("ğŸ“Š ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒå›¾è¡¨...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if save_plots:
            os.makedirs(output_dir, exist_ok=True)
        
        df = self.comparison_data
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Solver Performance Comparison Analysis', fontsize=16, fontweight='bold')
        
        # 1. æ±‚è§£æ—¶é—´æ¯”è¾ƒ
        ax1 = axes[0, 0]
        solver_times = df.groupby('solver_name')['solve_time'].mean()
        bars1 = ax1.bar(solver_times.index, solver_times.values, 
                       color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'][:len(solver_times)])
        ax1.set_title('Average Solve Time Comparison')
        ax1.set_ylabel('Time (seconds)')
        ax1.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.3f}', ha='center', va='bottom')
        
        # 2. ç›®æ ‡å€¼æ¯”è¾ƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        ax2 = axes[0, 1]
        if 'objective_value' in df.columns and df['objective_value'].notna().any():
            solver_objs = df.groupby('solver_name')['objective_value'].mean()
            bars2 = ax2.bar(solver_objs.index, solver_objs.values,
                          color=['#9b59b6', '#34495e', '#16a085', '#e67e22'][:len(solver_objs)])
            ax2.set_title('Average Objective Value Comparison')
            ax2.set_ylabel('Objective Value')
            ax2.tick_params(axis='x', rotation=45)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars2:
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.0f}', ha='center', va='bottom')
        else:
            ax2.text(0.5, 0.5, 'No Objective Value Data', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('Objective Value Comparison')
        
        # 3. æ±‚è§£æ—¶é—´åˆ†å¸ƒç®±å‹å›¾
        ax3 = axes[1, 0]
        solve_times_list = [df[df['solver_name'] == solver]['solve_time'].values 
                           for solver in df['solver_name'].unique()]
        box_plot = ax3.boxplot(solve_times_list, labels=df['solver_name'].unique(), patch_artist=True)
        
        # è®¾ç½®ç®±å‹å›¾é¢œè‰²
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        for patch, color in zip(box_plot['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        ax3.set_title('Solve Time Distribution')
        ax3.set_ylabel('Time (seconds)')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. æˆåŠŸç‡æ¯”è¾ƒ
        ax4 = axes[1, 1]
        success_rates = []
        solver_names = df['solver_name'].unique()
        
        for solver in solver_names:
            solver_data = df[df['solver_name'] == solver]
            success_rate = len(solver_data[solver_data['status'] == 'Optimal']) / len(solver_data) * 100
            success_rates.append(success_rate)
        
        bars4 = ax4.bar(solver_names, success_rates, 
                       color=['#27ae60', '#c0392b', '#8e44ad', '#d35400'][:len(solver_names)])
        ax4.set_title('Success Rate Comparison')
        ax4.set_ylabel('Success Rate (%)')
        ax4.set_ylim(0, 105)
        ax4.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars4:
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}%', ha='center', va='bottom')
        
        plt.tight_layout()
        
        if save_plots:
            filepath = os.path.join(output_dir, 'performance_comparison.png')
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ å›¾è¡¨å·²ä¿å­˜åˆ°ï¼š{filepath}")
        
        plt.show()
    
    def save_detailed_report(self, output_dir="results"):
        """
        ä¿å­˜è¯¦ç»†çš„åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
        """
        if not self.results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ±‚è§£ç»“æœ")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜CSVæ–‡ä»¶
        df = pd.DataFrame(self.results)
        csv_path = os.path.join(output_dir, 'solver_comparison_results.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°ï¼š{csv_path}")
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report_path = os.path.join(output_dir, 'performance_report.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("ç”Ÿäº§è®¡åˆ’ä¼˜åŒ–é—®é¢˜æ±‚è§£å™¨æ€§èƒ½æ¯”è¾ƒæŠ¥å‘Š\n")
            f.write("="*80 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            f.write("1. æ±‚è§£å™¨åŸºæœ¬ä¿¡æ¯\n")
            f.write("-" * 40 + "\n")
            
            for solver in df['solver_name'].unique():
                solver_data = df[df['solver_name'] == solver]
                success_rate = len(solver_data[solver_data['status'] == 'Optimal']) / len(solver_data) * 100
                avg_time = solver_data['solve_time'].mean()
                f.write(f"{solver:15s}: æˆåŠŸç‡ {success_rate:5.1f}%, å¹³å‡æ±‚è§£æ—¶é—´ {avg_time:.3f}ç§’\n")
            
            f.write("\n2. æ€§èƒ½æ’å\n")
            f.write("-" * 40 + "\n")
            
            # æŒ‰æ±‚è§£æ—¶é—´æ’å
            time_ranking = df.groupby('solver_name')['solve_time'].mean().sort_values()
            f.write("æ±‚è§£é€Ÿåº¦æ’åï¼ˆå¹³å‡æ—¶é—´ï¼‰ï¼š\n")
            for i, (solver, time_val) in enumerate(time_ranking.items(), 1):
                f.write(f"  {i}. {solver}: {time_val:.3f}ç§’\n")
            
            # ç»“è®ºå’Œå»ºè®®
            f.write("\n3. ç»“è®ºå’Œå»ºè®®\n")
            f.write("-" * 40 + "\n")
            fastest_solver = time_ranking.index[0]
            f.write(f"â€¢ æœ€å¿«çš„æ±‚è§£å™¨ï¼š{fastest_solver} ({time_ranking.iloc[0]:.3f}ç§’)\n")
            f.write(f"â€¢ å»ºè®®ï¼šå¯¹äºç±»ä¼¼è§„æ¨¡çš„ç”Ÿäº§è®¡åˆ’é—®é¢˜ï¼Œæ¨èä½¿ç”¨{fastest_solver}æ±‚è§£å™¨\n")
            f.write(f"â€¢ æ•°æ®è§„æ¨¡ï¼š{df['problem_name'].iloc[0]}\n")
            f.write(f"â€¢ æµ‹è¯•æ±‚è§£å™¨æ•°é‡ï¼š{len(df['solver_name'].unique())}\n")
        
        print(f"ğŸ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{report_path}")
    
    def analyze_scalability(self, scenarios_results):
        """
        åˆ†ææ±‚è§£å™¨çš„å¯æ‰©å±•æ€§
        
        å‚æ•°:
            scenarios_results: å¤šåœºæ™¯æµ‹è¯•ç»“æœ {scenario_name: results_list}
        """
        print("ğŸ“ˆ åˆ†ææ±‚è§£å™¨å¯æ‰©å±•æ€§...")
        
        scalability_data = []
        
        for scenario_name, results in scenarios_results.items():
            for result in results:
                if result:
                    scalability_data.append({
                        'scenario': scenario_name,
                        'solver': result['solver_name'],
                        'problem_size': result.get('time_periods', 0),
                        'solve_time': result.get('solve_time', 0),
                        'objective_value': result.get('objective_value', 0)
                    })
        
        if not scalability_data:
            print("âŒ æ²¡æœ‰å¯æ‰©å±•æ€§åˆ†ææ•°æ®")
            return
        
        df_scale = pd.DataFrame(scalability_data)
        
        # ç»˜åˆ¶å¯æ‰©å±•æ€§å›¾è¡¨
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        for solver in df_scale['solver'].unique():
            solver_data = df_scale[df_scale['solver'] == solver]
            plt.plot(solver_data['problem_size'], solver_data['solve_time'], 
                    'o-', label=solver, linewidth=2, markersize=8)
        plt.xlabel('Problem Size (Number of Periods)')
        plt.ylabel('Solve Time (seconds)')
        plt.title('Solve Time vs Problem Size')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 2)
        # æ—¶é—´å¤æ‚åº¦åˆ†æ
        for solver in df_scale['solver'].unique():
            solver_data = df_scale[df_scale['solver'] == solver].sort_values('problem_size')
            if len(solver_data) > 1:
                # è®¡ç®—æ—¶é—´å¢é•¿ç‡
                time_growth = np.diff(solver_data['solve_time']) / np.diff(solver_data['problem_size'])
                plt.plot(solver_data['problem_size'].iloc[1:], time_growth, 
                        's-', label=f'{solver} Growth Rate', alpha=0.7)
        plt.xlabel('Problem Size (Number of Periods)')
        plt.ylabel('Time Growth Rate (sec/period)')
        plt.title('Time Growth Rate Analysis')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print("âœ… å¯æ‰©å±•æ€§åˆ†æå®Œæˆ")


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    analyzer = PerformanceAnalyzer()
    
    # æ¨¡æ‹Ÿä¸€äº›æµ‹è¯•ç»“æœ
    test_results = [
        {'solver_name': 'MILP', 'status': 'Optimal', 'solve_time': 0.5, 'objective_value': 15000},
        {'solver_name': 'LP', 'status': 'Optimal', 'solve_time': 0.2, 'objective_value': 14500},
    ]
    
    for i, result in enumerate(test_results):
        analyzer.add_result(result['solver_name'], f"æµ‹è¯•é—®é¢˜{i+1}", result)
    
    # ç”ŸæˆæŠ¥å‘Š
    df = analyzer.generate_comparison_report()
    if df is not None:
        analyzer.plot_performance_charts(save_plots=False)
        print("ğŸ§ª æ€§èƒ½åˆ†æå™¨æµ‹è¯•å®Œæˆ") 